Computational Linguistics, Fall 2021

Haverford College

J&M 3rd Edition Book Draft: https://web.stanford.edu/~jurafsky/slp3/

Python Tutorial: https://www.learnpython.org/

# Schedule of Topics (Preliminary)

In general, the schedule is organized as: foundations, language models, linear models for text, neural networks, deep learning approaches, applications, and special topics.

| Date  | Topic                                                        | Read/View Before Class                                       | Lab                                                     |      | Due                                                          |
| ----- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------- | ---- | ------------------------------------------------------------ |
| 8/30  | Introductions, Command line, SSH, What is Computational Linguistics? | [Syllabus](syllabus.md)                                      | [Lab 0: Computer/Remote  Setup, SSH](labs/lab0.md)      |      |                                                              |
| 9/1   | Regular Expressions, Probabilistic Finite State Machines Intro, Probability Intro | [Command Line Ch. 1 & 2](https://www.learnenough.com/command-line-tutorial/basics);  [Functions](https://www.youtube.com/watch?v=MjeXZ7Ea89g), | [Lab 1: Command Line and I/O Redirection](labs/lab1.md) |      | HW0: Command Line Discussion Board (Wednesday), [Lab 1](labs/lab1.md) (Friday) |
| 9/8   | Text-mode Editing, Python, Basic Probability, Conditional Probability | [Regular Expressions Notes (Piazza)](https://piazza.com/class_profile/get_resource/kcxiq6ijb2q5t/kex7ykctfdx57c) and/or J&M 2.1; J&M 2.2, 2.3, 2.4.1, 2.4.2, 2.4.4 | [Lab 2: Python Markov Text Generation](labs/lab2.md)    |      | [HW1: Regular Expressions](https://piazza.com/class_profile/get_resource/ksysw5gb2e13q7/kt27xmayn19z); |
| 9/13  | [Language Models and Probability](https://piazza.com/class_profile/get_resource/kcxiq6ijb2q5t/kf8ets0a6t1tv | [A Probability Primer](https://www.sjsu.edu/faculty/gerstman/StatPrimer/probability.pdf); [Distributions](https://www.youtube.com/watch?v=qc5QewourIU&feature=youtu.be) |                                                         |      |                                                              |
| 9/15  | Geometric Intuition Continued; Classification with Linear Perceptron and Geometric Intuition; Classification Introduction | [Language Modeling Primer](https://piazza.com/class_profile/get_resource/ksysw5gb2e13q7/ktbthuoiq73op) (Optional); [J&M 3.1-3.4](https://web.stanford.edu/~jurafsky/slp3/3.pdf) | [Lab 3: Corpus Exploration](labs/lab3.md)               |      | Lab 2                                                        |
| 9/20  | [Logistic Regression with Stochastic Gradient Descent](https://piazza.com/class_profile/get_resource/kcxiq6ijb2q5t/kfhn44yucmk48t) | [Vectors](https://www.youtube.com/watch?v=kXLGnrzw1zk); [Matrices](https://www.youtube.com/watch?v=LEJpb8v_RQQ); [Prediction Primer](https://piazza.com/class_profile/get_resource/kcxiq6ijb2q5t/kfdytve4qul29w);  [J&M 5.1-5.3](https://web.stanford.edu/~jurafsky/slp3/5.pdf) |                                                         |      |                                                              |
| 9/22  | In-class Collaborative Exercises on Material Up to Now       | [Derivatives and Optimization](https://www.youtube.com/watch?v=TG6PIKulK0Q); [Logistic Regression with Stochastic Gradient Descent Notes](https://piazza.com/class_profile/get_resource/kcxiq6ijb2q5t/kfhn4zorp646dt) (Optional); J&M 5.5-5.7; J&M 6.1 | [Lab 4: Basic Classification](labs/lab4.md)             |      | Lab 3<br />HW2 (Friday)                                      |
| 9/27  | Review of Python, Command Line, and Working Remotely,<br />Word Embeddings | [Word Embeddings Primer](https://piazza.com/class_profile/get_resource/kcxiq6ijb2q5t/kfs9ejn2pjo34s) (Optional), |                                                         |      |                                                              |
| 9/29  | Word Embeddings, Pointwise Mutual Information                | <br />J&M 6.2-6.4                                            | [Lab 5: Word Embeddings Exploration](labs/lab5.md)      |      |                                                              |
| 10/4  | Multiclass Classification and Neural Networks, Neural Language Models | J&M 6.6-6.10                                                 |                                                         |      |                                                              |
| 10/6  | Final Projects, Race After Technology Intro, Neural Networks | Benjamin Introduction                                        |                                                         |      |                                                              |
| 10/18 | Neural Networks; Race After Technology Ch. 1                 | Benjamin Ch. 1; [Multiclass Classification and Neural Networks Primer](https://piazza.com/class_profile/get_resource/kcxiq6ijb2q5t/kfxzq9q9oxx674) |                                                         |      | Benjamin Ch. 1 Discussion Questions                          |
| 10/20 | Neural Language Models; Intro. to CL Research                | Review J&M 7 and previous material as necessary; [Introduction to Keras for Researchers](https://keras.io/getting_started/intro_to_keras_for_researchers/) | Lab: HW3 Homework Help                                  |      | Lab 5                                                        |
| 10/25 | Recurrent Neural Networks                                    | [Illustrated Guide to RNNs](https://www.youtube.com/watch?v=LHXXI4-IEns); [Merullo et al. (2019)](https://arxiv.org/pdf/1909.03343.pdf) |                                                         |      | [HW4: Neural Text Classification](https://piazza.com/class_profile/get_resource/ksysw5gb2e13q7/kufnzv5gkaq1lr) |
| 10/27 | LSTMs and GRUs; [Statistical Machine Translation](http://www.statmt.org/book/slides/04-word-based-models.pdf) and the Noisy Channel Model | [Illustrated Guide to LSTMs and GRUs](https://www.youtube.com/watch?v=8HyCNIVRbSU);  [Understanding LSTMs](https://web.stanford.edu/class/cs379c/archive/2018/class_messages_listing/content/Artificial_Neural_Network_Technology_Tutorials/OlahLSTM-NEURAL-NETWORK-TUTORIAL-15.pdf) |                                                         |      |                                                              |
| 11/1  | Race After Technology, Ch. 2; Neural Machine Translation     | Benjamin Ch. 2; [Brown (1990)](https://www.ling.upenn.edu/courses/Spring_2011/cogs502/Brown1990.pdf) |                                                         |      | [Brown (1990) Reading Questions](hw/brown_reading.md)            |
| 11/3  | Sequence-to-sequence Models, Machine Translation             | J&M 10                                                       |                                                         |      | Lab 6: LSTM Text Generation                                  |
| 11/8  | Naive Bayes; Part-of-speech Tagging                          |                                                              |                                                         |      |                                                              |
| 11/10 | Information Theory 1                                         |                                                              |                                                         |      |                                                              |
| 11/15 | Race After Technology, Ch. 3; Final Project Discussion       | Benjamin 3                                                   |                                                         |      |                                                              |
| 11/17 | Information Theory 2                                         |                                                              |                                                         |      |                                                              |
| 11/13 | Topic Modeling                                               |                                                              |                                                         |      | Piazza Discussion, **Final Project Proposal**                |
| 11/17 | Constituency Grammars                                        | [J&M 12.1-12.2](https://web.stanford.edu/~jurafsky/slp3/12.pdf) |                                                         |      |                                                              |
| 11/22 | Constituency Grammars 2                                      | [J&M 12.3-12.5](https://web.stanford.edu/~jurafsky/slp3/12.pdf) |                                                         |      | **Introduction and Related Work Draft**                      |
| 11/29 | Constituency Parsing                                         | J&M 13.1, 13.3, 13.4                                         |                                                         |      |                                                              |
| 12/1  | Semantics                                                    | [Computational Semantics, Chapter 2](http://www.coli.uni-saarland.de/projects/milca/courses/comsem/pspdf/main.pdf) |                                                         |      |                                                              |
| 12/6  | Large Language Models                                        |                                                              |                                                         |      |                                                              |
| 12/8  | Green NLP                                                    |                                                              |                                                         |      |                                                              |
|       |                                                              |                                                              |                                                         |      |                                                              |
|       |                                                              |                                                              |                                                         |      |                                                              |
|       |                                                              |                                                              |                                                         |      |                                                              |
|       |                                                              |                                                              |                                                         |      |                                                              |
|       |                                                              |                                                              |                                                         |      |                                                              |